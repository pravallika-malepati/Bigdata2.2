                                                      Assignment 2.2

1)HDFS:
            1. HDFS is a Hadoop  Distributed File System used for Storing very large amount of data like terabytes and petabytes of data.
            2.HDFS is fault tolerant and provides high-throughput access to large data sets. 
            3.This article explores the primary features of HDFS and provides a high-level view of the HDFS architecture.HDFS stores the data in the the                 consecutive blocks . sothe time to seek the data is less when compared to the filesystem.
            4.


2)Hadoop Cluster:
                            1.Normally any set of computers that work together as a single system is called Cluster. A computer cluster used for Hadoop is called                               Hadoop Cluster. 
                            2. Hadoop cluster is a special type of computational cluster designed for storing and analyzing large  amount of unstructured data in a                               distributed computing environment. These clusters run on low cost commodity computers. 
                            3. Large Hadoop Clusters are arranged in several racks. Network traffic between different nodes in the same rack is much more desirable                                 than network traffic across the racks. 

3)Hadoop Blocks:
                             Hadoop distributed file system also stores the data in terms of blocks. However the block size in HDFS is very large. The default size of HDFS block is 64MB. The files are split into 64MB blocks and then stored into the hadoop filesystem. The hadoop application is responsible for distributing the data blocks across multiple nodes.

Advantages of Hadoop blocks:
            1.The blocks are of fixed size, so it is very easy to calculate the number of blocks that can be stored on a disk.
             2.Blocks are easy to replicate between the datanodes and thus provide fault tolerance and high availability   

